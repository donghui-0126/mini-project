{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 세션 4 과제\n",
        "\n",
        "나이키 신발들의 이름 데이터를 받아와서, 리셀 가격을 맞춰보는 NLP 과제입니다. "
      ],
      "metadata": {
        "id": "T0lMOLSaKMdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 모듈 임포트\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Exm6F7B8KiQl"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drive 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRpdVSSqOKE7",
        "outputId": "f7535d3d-4c3a-4ccd-ef20-0276d219f826"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 구글 드라이브에서 데이터셋을 가져오자 \n",
        "# index_col은 가져올 때 새로운 column이 생기지 않게 하기 위함이다.\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_data', index_col=0)"
      ],
      "metadata": {
        "id": "DzCg9cUtKl5w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가져온 데이터프레임을 살펴보자\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "zA-hHSQOOT_h",
        "outputId": "ea2f85f4-b181-4ab0-c3bb-1fa6659d52a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             name  price_resell\n",
              "0       Nike Dunk Low Retro Black        152800\n",
              "1  Nike Air Force 1 '07 Low White        136200\n",
              "2    Nike Air Force 1 '07 WB Flax        173200"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6ebc538-d9a4-4f07-bf75-30c02bca8122\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>price_resell</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Nike Dunk Low Retro Black</td>\n",
              "      <td>152800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nike Air Force 1 '07 Low White</td>\n",
              "      <td>136200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Nike Air Force 1 '07 WB Flax</td>\n",
              "      <td>173200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6ebc538-d9a4-4f07-bf75-30c02bca8122')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6ebc538-d9a4-4f07-bf75-30c02bca8122 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6ebc538-d9a4-4f07-bf75-30c02bca8122');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_data = df['price_resell']"
      ],
      "metadata": {
        "id": "Xiij4JgUTjsh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data_preprocess"
      ],
      "metadata": {
        "id": "GyvXMENCRfal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer에 fit 하기 위해서 데이터 프레임의 name 컬럼의 값을 가져옴.\n",
        "names = df['name'].values\n",
        "\n",
        "print(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG9KMpyjPOqa",
        "outputId": "b3ac16bb-920a-4699-8d78-684fb65cd9ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nike Dunk Low Retro Black' \"Nike Air Force 1 '07 Low White\"\n",
            " \"Nike Air Force 1 '07 WB Flax\" ...\n",
            " 'Nike x Diamond Supply Co. SB Dunk High Tiffany'\n",
            " 'Nike Roshe One Black Anthracite Sail'\n",
            " 'Nike Air Force 1 High Premium Le Work Boot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences로 tokenizer를 fit 해준다.  \n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(names)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(f\"word_index의 크기: {len(word_index)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kvb108FKOZCG",
        "outputId": "2a7bceba-e69a-4a64-91c8-ee4c1dd2616c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_index의 크기: 1172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 토큰화 한다.\n",
        "tokenized_name = tokenizer.texts_to_sequences(names)\n",
        "tokenized_name[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEBxmBJ9QdRd",
        "outputId": "8d3fd83e-cd72-4934-87b9-cf712360a3e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 7, 5, 17, 9],\n",
              " [1, 2, 6, 4, 11, 5, 8],\n",
              " [1, 2, 6, 4, 11, 362, 187],\n",
              " [1, 3, 40, 2, 6, 4, 5, 187],\n",
              " [1, 18, 164, 61, 26, 25, 142, 252, 13, 660, 661]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 한 문장을 padding 해준다. \n",
        "padded_name = pad_sequences(tokenized_name)\n",
        "padded_name[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2mdE8xZQsSV",
        "outputId": "523501c5-a0cd-427e-efb4-5a5992e9e20f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   7,   5,\n",
              "         17,   9],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   6,   4,  11,\n",
              "          5,   8],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   6,   4,  11,\n",
              "        362, 187],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   1,   3,  40,   2,   6,   4,\n",
              "          5, 187],\n",
              "       [  0,   0,   0,   0,   1,  18, 164,  61,  26,  25, 142, 252,  13,\n",
              "        660, 661]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_name.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtt8e9QbQ93q",
        "outputId": "c904a2f2-4edc-4e69-8bf3-1b9329ff0819"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1455, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modeling"
      ],
      "metadata": {
        "id": "xh6w9obDRC9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# 임베딩 층에 입력될 단어의 수를 지정한다.\n",
        "word_size = len(word_index) + 1\n",
        "\n",
        "# train_data, test_data를 나눈다.\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(padded_name, target_data, test_size=0.3, random_state=42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    # 임베딩층\n",
        "    keras.layers.Embedding(word_size, word_size, input_length=15),\n",
        "    # 회귀를 위해 임베딩층의 output값을 1차원의 array로 바꾸어준다. \n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(16),\n",
        "    keras.layers.Dropout(0.5), # 과적합 방지를 위해서 넣는 층.\n",
        "    keras.layers.Dense(4),\n",
        "    keras.layers.Dropout(0.5), # 과적합 방지를 위해서 넣는 층.\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# MAPE 를 사용한다.\n",
        "# 예측 값과의 오차를 % 로 알려주는 손실함수이다.\n",
        "# 더 직관적으로 오차를 알 수 있다.\n",
        "model.compile(optimizer='adam', loss= keras.losses.MeanAbsolutePercentageError())\n",
        "model.fit(train_X, train_y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srwlIGlaRi7u",
        "outputId": "3323fc4a-f6cf-4faa-920d-7c3115da57e7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 3s 40ms/step - loss: 99.9807\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 99.8266\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 99.2280\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 97.4999\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 94.1625\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 87.5635\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 75.6198\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 64.0247\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 58.3810\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 56.1280\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 56.7858\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 55.7897\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 55.6357\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 1s 36ms/step - loss: 52.8381\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 56.1373\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 54.3098\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 1s 36ms/step - loss: 54.8354\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 54.3759\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 54.4883\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 55.0852\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 55.3533\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 53.4023\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 53.1120\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 54.6824\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 53.7423\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 52.6726\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 50.4310\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 51.9454\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 52.2630\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 53.0627\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 52.6123\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 51.5940\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 51.8403\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 52.9207\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 52.5085\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 51.6718\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 52.6022\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 50.0788\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 51.2177\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 51.8017\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 50.1256\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 50.4643\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 51.2676\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 49.8420\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 49.1827\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 49.7328\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 48.9257\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 48.4009\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 1s 24ms/step - loss: 49.7535\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 50.1202\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 49.9988\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 49.0185\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 48.3342\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 49.0253\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 48.8860\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 49.9005\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 49.9629\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 48.1069\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 49.3086\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 1s 31ms/step - loss: 47.7031\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 46.7091\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 49.3249\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 48.0974\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 47.0509\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 49.0137\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 48.0119\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.7625\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.6553\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.0649\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 48.1640\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.6037\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.9899\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 1s 36ms/step - loss: 48.1462\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 47.5202\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 2s 55ms/step - loss: 45.8097\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 1s 39ms/step - loss: 47.5917\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 46.0362\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.7024\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 49.0747\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 47.6832\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 46.4183\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 46.8454\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 46.8879\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 46.8837\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.9824\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 46.1641\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 47.6466\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 45.3854\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 45.4795\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 1s 37ms/step - loss: 46.3156\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 46.8993\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 45.6121\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 45.3550\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 46.0497\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 46.4427\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 46.8415\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 45.5157\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 45.8142\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 46.7265\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 46.0303\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba1c1bab50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model evaluate"
      ],
      "metadata": {
        "id": "mrXOVIDbjCsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 오차는 대략 30% 로 나온다. \n",
        "model.evaluate(test_X, test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAPBprZlhWqS",
        "outputId": "17290b0f-74ea-462a-9fcf-21d300ea944c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 0s 3ms/step - loss: 32.9089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32.908931732177734"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 신발 가격 예측 해보기\n",
        "\n",
        "과제 하느라 수고하셨습니다! \n",
        "\n",
        "아래는 위 학습된 모델을 통해서 예측을 진행해주는 함수입니다.\n",
        "\n",
        "여러분들이 상상한 신발의 리셀가격은 얼마인지 확인해보세요!\n",
        "\n",
        "PS) word_index 안에 있는 단어만으로 구성되어야 예측이 더 자연스러워집니다. "
      ],
      "metadata": {
        "id": "-OxRKFnGokAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction(name):\n",
        "    tokenized_name = tokenizer.texts_to_sequences([name])\n",
        "    padded_name = pad_sequences(tokenized_name, 15).reshape((-1,15))\n",
        "    pred = model.predict(padded_name)\n",
        "    return pred"
      ],
      "metadata": {
        "id": "pOpEjYXtnS-j"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_prediction('Nike x off white x chicago x kobe x stussy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE3m6WqLn1-E",
        "outputId": "db9be5da-e9c2-4e86-e6ec-9939d71bbd70"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 70ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[280049.38]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3YBH6PApD1D",
        "outputId": "b06503b7-448e-4ddf-c357-030722b39d99"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['nike', 'air', 'x', '1', 'low', 'force', 'dunk', 'white', 'black', 'max', \"'07\", 'sb', 'and', 'high', 'grey', 'sp', 'retro', 'zoom', 'red', 'blue', 'mid', '2', 'pro', '97', 'light', 'prm', 'sail', 'se', 'green', 'lv8', 'blazer', '95', 'qs', 'orange', 'acg', 'university', 'off', 'lebron', 'next', 'supreme', 'sacai', 'more', 'uptempo', 'flyknit', 'og', 'dark', 'gold', 'of', 'navy', 'trainer', 'ep', '90', 'react', 'plus', 'waffle', 'stussy', 'pink', 'brown', 'triple', 'daybreak', '5', 'gore', 'tex', 'lx', 'racer', 'royal', 'silver', 'purple', '2020', 'tailwind', 'midnight', 'club', 'smoke', 'undercover', 'the', 'pack', 'fear', 'god', 'vapormax', 'volt', 'olive', 'bone', 'mountain', 'fly', '96', '79', 'comme', 'des', 'garcons', 'premium', 'metallic', 'color', 'team', 'summit', '3', 'yellow', 'platinum', \"'77\", 'element', 'day', 'pure', 'hyper', 'kobe', 'multi', 'varsity', '2018', 'crimson', '98', 'pegasus', '87', 'cortez', 'fog', 'ldwaffle', 'emb', 'zoomx', '2021', 'wolf', '0', 'killshot', 'vaporfly', 'protro', 'presto', 'one', 'camo', 'homme', 'desert', 'nature', 'space', '2017', 'vast', 'anniversary', 'anthracite', 'a', 'court', 'alphafly', 'total', 'ispa', 'obsidian', 'medium', 'nrg', 'stone', 'iron', 'halloween', 'bright', 'cool', 'vaporwaffle', '18', 'championship', 'fossil', 'phantom', 'g', 'overbreak', 'slide', 'atmos', 'gym', 'ambush', 'terra', 'xx', 'leather', 'gt', 'wheat', 'terrascape', 'acronym', 'vomero', '40th', 'join', 'forces', '15', 'travis', 'scott', 'clot', 'nba', 'gum', 'pine', 'shox', 'kd', 'classic', 'rattan', 'game', '1985', '4', 'all', 'challenger', 'moon', 'stranger', 'things', 'flax', 'athletic', '50', 'hot', 'kasina', 'craft', 'south', 'milk', 'pearl', 'slate', 'barely', '9', 'vintage', 'kyrie', 'benassi', '83', 'huarache', 'be', 'swoosh', 'jam', 'm', 'cut', 'jumbo', 'experimental', 'hippie', 'chocolate', 'penny', 'mercurial', 'vapor', 'tf', 'fragment', 'lot', 'spiridon', 'kukini', 'union', 'sesame', 'maroon', '6', 'khaki', 'month', 'sun', 'deep', 'coconut', 'snake', 'mada', 'woven', 'first', 'use', 'photon', 'dust', 'wash', 'infinity', 'mowabb', 'running', 'offline', 'noir', 'teal', 'tan', 'type', 'photo', 'matthew', 'williams', 'habanero', 'sea', 'foamposite', 'ore', 'ii', '2022', 'night', 'violet', 'rush', 'hemp', 'neon', 'special', 'foam', 'patta', 'pale', 'dusty', 'maize', 'tempo', 'pg', 'lowcate', '8', 'boot', 'xix', 'trail', 'm2k', 'tekno', 'beetroot', 'limestone', 'concepts', 'velvet', 'mineral', 'armory', 'curry', 'star', 'solar', 'glass', 'new', 'baroque', '2016', 'lunar', 'flight', 'thunder', 'malachite', 'tom', 'sachs', 'shoe', 'sulfur', 'vivid', 'peaceminusone', 'noise', 'drake', 'nocta', 'billie', 'eilish', 'marina', 'ride', 'have', 'won', 'ang', 'particle', 'gorge', 'psychic', 'flash', '2019', 'ochre', 'sense', 'jay', 'rose', 'box', 'cactus', 'ivory', 'what', 'essential', 'monarch', 'sf', 'lemon', 'safari', '14', 'run', 'copy', 'paste', 'mars', 'washed', 'vachetta', 'chlorophyll', 'true', 'nyc', 'gaiadome', 'paul', 'slam', '270', 'grape', '004', 'strike', 'acid', 'clear', 'korea', 'kith', 'free', 'v2', 'world', 'flyleather', 'duck', 'reflective', 'laser', 'adapt', 'bb', 'kr', 'charger', 'vs', 'skepta', 'roshe', '2015', 'wb', '2023', 'para', 'cream', 'sunder', 'valerian', 'neutral', 'citron', 'kentucky', 'bullet', 'sequoia', 'jacquemus', 'humara', '2013', 'step', 'seoul', 'parra', 'apple', 'passport', 'fuchsia', 'with', 'gift', 'cage', 'tint', 'chill', 'mystic', 'suptempo', 'luxe', 'flea', 'bred', 'ghost', 'jump', 'stitch', 'turquoise', 'tl', 'v', '7', 'neptune', 'familia', 'skeleton', '03', 'lime', 'freak', '720', 'beach', 'debut', 'exclusive', 'le', 'ale', 'iso', 'rubber', 'chrome', 'college', 'siren', 'out', 'pecan', 'viotech', 'scorpion', 'midsole', 'nh', 'animal', 'canyon', 'legend', 'cosmic', 'paris', 'scrap', 'pulse', 'zebra', 'denim', 'moc', 'gundam', 'pineapple', 'by', 'any', 'means', 'do', 'upside', 'down', 'moccasin', 'link', 'golf', 'hawkins', 'school', 'amarillo', 'burrow', 'vortex', 'orewood', 'ruohan', 'wang', '01', 'tinker', 'sketch', 'to', 'shelf', 'cold', 'wall', 'beige', '17', 'ld', '1000', 'starfish', 'dog', '180', 'diamond', 'general', 'purpose', 'jackpot', 'blast', 'blackened', 'cact', 'us', 'coastal', 'syracuse', 'mushroom', 'noble', 'j', 'crew', 'clay', 'fresh', 'huf', 'string', 'mantra', 'patent', 'hazel', 'praline', 'glacier', 'beast', 'argon', 'bulls', 'chicago', 'pippen', 'champ', 'spark', 'sean', 'regular', 'cocoa', 'big', 'plant', 'market', 'forest', 'elite', 'spruce', 'radiant', 'popcorn', 'manoa', 'lilac', 'glow', 'iv', 'christmas', 'bag', 'chalk', 'frost', 'blaze', 'rayguns', 'cider', 'suede', 'stadium', 'overreact', 'jade', 'atmosphere', 'terminator', 'ltr', 'kaws', 'rust', 'coriander', 'crater', 'siempre', 'home', 'tokyo', '23', '39', 'love', 'action', 'dawn', 'hangul', 'magma', 'void', 'barber', 'shop', 'forma', 'uno', 'vntg', 'paisley', 'jean', 'gaultier', \"valentine's\", 'readymade', 'driftwood', '005', 'trails', 'culture', 'skate', 'adjust', 'bruce', 'lee', 'graffiti', 'mint', 'yard', 'plum', '99', 'd', 'persian', 'raid', 'strawberry', 'romaleos', 'pollen', 'unity', 'champions', 'york', 'bodega', 'basalt', 'legacy', 'tune', 'squad', 'reverse', 'nylon', 'london', 'summer', 'hawaii', 'lagoon', 'puerto', 'rico', 'skylon', 'coast', 'unicorn', 'denham', 'test', 'time', 'arctic', 'kim', 'jones', 'limelight', 'go', 'flyease', 'sprung', 'olympic', 'honeydew', 'carhartt', 'wip', 'island', 'win', 'dsm', 'infrared', 'lakers', 'kendrick', 'lamar', 'dynamic', 'oreo', 'magic', 'fpar', 'shroud', 'enamel', 'worldwide', 'duckboot', 'kelp', 'orbit', 'silk', 'ron', 'english', 'gyakusou', 'brs', 'medicom', 'toy', 'rbrick', 'electric', '16', 'af100', 'gump', 'ishod', 'wair', 'cross', 'label', 'in', 'independence', 'burgundy', 'crush', 'russet', 'gts', 'generation', 'enigma', '02', 'n', '354', 'indigo', 'vulc', 'king', 'cork', 'walker', 'supply', 'co', 'edge', 'hack', 'just', 'ny', 'shima', 'mango', 'bb4', 'comet', 'flat', 'fewter', 'archive', 'kwondo1', 'certified', 'lover', 'boy', 'why', 'so', 'sad', 'mummy', 'chile', 'pojangmacha', 'nets', 'sandy', 'metalic', \"80's\", 'bus', 'iris', 'tour', 'san', 'francisco', 'villain', 'abstract', 'art', 'screem', 'veneer', 'cognac', 'crepe', 'cave', 'shamrock', 'bronx', 'origins', 'atlantic', 'voltage', 'goldenrod', '46', 'scottie', 'martine', 'mr4', '5x', 'wotherspoon', 'strangelove', 'asia', 'stage', 'spades', '11', '4kb', 'horse', 'coffee', 'brazil', 'hello', 'kitty', 'timeless', 'lucid', '12', 'pistachio', 'vanilla', 'adobe', 'haystack', 'raspberry', 'infinite', 'spartan', 'barcelona', 'weekend', 'campout', '2014', 'oil', 'pig', 'b', 'cargo', 'cacao', 'wow', 'celery', 'grand', 'miami', 'nights', '37', 'lbj', 'surf', 'turf', 'titan', 'beyond', 'seas', 'rebel', 'skulls', '36', 'gtx', 'galactic', 'nxt', 'haze', 'sage', 'carabiner', 'aunt', 'journey', 'reward', 'seasonal', 'legal', 'sunset', 'gradient', 'riftblue', 'invincible', 'archaeo', 'venice', 'rough', 'blueberry', 'granite', 'somos', 'dia', 'de', 'muertos', 'froskate', 'water', 're', 'raw', 'kumquat', 'pogo', 'satrn', 'xt', 'flux', 'madder', 'root', 'worn', 'p', '6000', 'lobster', 'aqua', 'road', 'sign', 'cliver', 'holiday', 'zest', 'british', 'oak', 'mellow', 'community', 'garden', 'size', 'cobalt', 'maximum', 'volume', 'ceramic', 'west', 'indies', 'net', 'vegas', 'bacon', 'wheels', 'tumbled', 'overcast', 'soulgoods', \"'90s\", 'like', 'girl', 'trading', 'cards', 'topaz', 'samba', 'snow', 'frame', 'habibi', 'polaroid', 'acorn', 'berry', 'birch', 'scarab', 'cheetah', 'remastered', 'overshoe', 'our', 'del', 'sol', 'ironstone', 'loud', 'industrial', 'crushed', 'c', 'rings', 'ben', \"jerry's\", 'chunky', 'dunky', 'chlorine', 'jack', 'social', 'status', 'lunch', 'mocha', 'rise', 'colin', 'kaepernick', 'la', 'mezcla', 'reed', 'barkroot', 'colors', 'heavy', 'celadon', 'street', 'hawker', 'maze', 'chaos', 'pass', 'port', 'asuna', 'shimmer', 'postal', 'mayumi', 'yamase', 'alternate', 'hoops', 'end', 'sour', 'gravity', 'mean', 'taupe', 'gnarhunters', 'twist', '49', 'ftc', 'skates', 'kebab', 'destroy', 'grateful', 'dead', 'bear', 'lavender', 'mist', \"hallow's\", 'eve', 'field', 'rx', 'shirt', 'escape', 'factor', 'ndstrkt', 'deschutz', 'mischief', 'sesh', '3m', 'computer', 'chip', 'pattern', 'shanghai', 'kaleidoscope', 'aura', 'around', 'shower', 'doraemon', 'susan', 'missing', 'staple', 'panda', 'pigeon', 'grim', 'reaper', 'elephant', 'ap', 'ocean', 'cube', 'sport', 'camcorder', 'peel', 'sand', 'pull', 'tab', 'old', 'valor', 'ash', 'quartersnacks', 'cake', 'treasure', 'eoi', 'greedy', 'chinese', 'year', 'longevity', 'menta', 'basic', 'slip', 'faust', 'kcdc', 'elemental', 'fruity', 'pebbles', 'toasty', 'artifact', 'landing', 'vision', 'george', 'bw', 'playstation', 'oatmeal', 'serena', 'queen', 'hong', 'kong', 'ten', 'roma', 'vista', 'canvas', 'touch', 'ac', 'kevin', 'hell', '55', 'jewel', 'mag', 'forrest', 'burn', '19', 'bugs', 'marvin', 'rooted', 'peace', 'notre', 'instant', 'skateboards', 'gunsmoke', 'peach', 'streak', 'spectrum', 'exotic', 'skins', '93', 'menthol', 'knicks', 'copper', 'sd', 'proto', 'bang', 'wile', 'e', 'roadrunner', 'ember', 'wizenard', 'parachute', 'pompidou', 'center', 'lakeside', 'ultra', 'pilgrim', 'man', 'machine', 'pre', 'atomic', 'seafoam', 'banshee', 'sports', 'bloody', 'active', 'carpet', 'company', 'horus', 'scream', 'valentine', 'alleyoop', 'tiger', 'rucker', 'park', 'zipper', '2090', '72', 'slim', 'works', 'progress', 'danny', 'supa', 'camp', 'snakeskin', 'yeezy', 'tiempo', 'delta', 'leopard', 'bronze', 'eclipse', 'nightmares', 'aimbot', 'nasu', '04', 'good', 'flow', 'oiive', 'rodriguez', 'boxing', 'nebula', 'antarctica', 'tulip', 'tidal', 'wave', 'stash', 'crystal', 'zip', 'nikola', 'jokic', 'hyperdunk', 'tropical', 'minneapolis', '38', 'zero', 'gaze', 'florida', 'horizon', 'ship', 'barley', 'moss', 'p22', 'pga', 'treeline', 'drifter', 'ntrl', 'turtle', 'milky', 'stork', 'matte', 'aluminum', 'ashen', 'magnus', 'urban', 'outlaw', 'fireberry', 'carnivore', 'lebronold', 'palmer', 'k', 'o', 'cha', 'mahogany', 'friends', 'family', 'mallard', 'pj', 'tucker', 'civilist', 'thermography', 'lost', 'found', 'era', 'bark', 'antarktik', 'charcoal', 'shibuya', 'gato', 'ultramarine', 'soulland', 'fri', 'part', 'don', 'chimera', 'print', 'sock', 'dart', 'rainbow', 'patch', 'cashmere', 'usa', 'bison', 'regal', 'mother', 'father', 'utility', 'alpha', '1017', 'alyx', '9sm', 'sylvester', 'tweety', 'dunkman', 'zaherra', 'opti', 'oracle', 'eliud', 'kipchoge', 'watermelon', 'mvp', 'cookies', 'jacket', 'fury', 'hennessy', 'country', 'croc', 'inside', 'ftb', 'lapis', 'toronto', 'raptors', 'obj', 'young', 'drip', 'john', 'elliott', 'icon', 'gobe', 'rokit', 'wildwood', 'pimento', 'emerald', 'r4', 'it', 'rainforest', 'eggplant', 'tz', 'faded', 'strong', 'nai', 'ke', 'unholy', 'cumulus', 'fuse', '10th', 'famous', 'tiffany', 'work'])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}